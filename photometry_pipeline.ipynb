{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8809851-36af-46d6-b165-1c09b16a05ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "import subprocess²\n",
    "from pathlib import Path\n",
    "from typing import Dict, Literal, Optional, Tuple, Union\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Third-party scientific computing imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sep\n",
    "\n",
    "# Visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sb\n",
    "\n",
    "# Astropy core imports\n",
    "import astropy.units as u\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS, utils\n",
    "from astropy.table import Table\n",
    "from astropy.nddata import NDData\n",
    "from astropy.stats import sigma_clipped_stats, SigmaClip\n",
    "from astropy.coordinates import SkyCoord, EarthLocation, AltAz, get_sun\n",
    "from astropy.time import Time\n",
    "from astropy.modeling import models, fitting\n",
    "from astropy.utils.exceptions import AstropyWarning\n",
    "from astropy.visualization import (\n",
    "    ImageNormalize, \n",
    "    ZScaleInterval, \n",
    "    HistEqStretch, \n",
    "    MinMaxInterval, \n",
    "    simple_norm\n",
    ")\n",
    "from astropy.convolution import Gaussian2DKernel, Tophat2DKernel, convolve\n",
    "from astropy.samp import SAMPIntegratedClient\n",
    "\n",
    "# Astroquery imports\n",
    "from astroquery.gaia import Gaia\n",
    "\n",
    "# Photutils imports\n",
    "from photutils import detection, aperture\n",
    "from photutils.utils import circular_footprint, calc_total_error\n",
    "from photutils.psf import (\n",
    "    EPSFBuilder,\n",
    "    PSFPhotometry,\n",
    "    IterativePSFPhotometry,\n",
    "    extract_stars,\n",
    "    make_psf_model\n",
    ")\n",
    "from photutils.segmentation import detect_threshold, detect_sources\n",
    "from photutils.background import Background2D, MedianBackground, SExtractorBackground\n",
    "\n",
    "# Other astronomy-specific imports\n",
    "from astroplan import Observer\n",
    "import astrometry\n",
    "import imexam\n",
    "from statsmodels import robust\n",
    "\n",
    "# Utilities imports\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Logging configuration\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Matplotlib configuration\n",
    "plt.style.use('default')\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (7, 5),\n",
    "    'font.size': 10,\n",
    "    'lines.linewidth': 2,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'axes.titlesize': 12,\n",
    "    'legend.fontsize': 8\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c9ad7d-eaff-4b1f-b547-f7c80b6c53d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_gaia(\n",
    "    ra: float, \n",
    "    dec: float, \n",
    "    focal_length: float,\n",
    "    sensor_size: float,\n",
    "    image_width: int,\n",
    "    mag_limit: float = 19.5,\n",
    "    bp_rp_min: float = -0.3,\n",
    "    bp_rp_max: float = 0.9\n",
    ") -> Optional[Table]:\n",
    "    \"\"\"\n",
    "    Interroge la base de données Gaia DR3 pour obtenir des sources stellaires non-variables\n",
    "    dans un champ de vue calculé à partir des paramètres optiques.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ra : float\n",
    "        Ascension droite du centre du champ (degrés)\n",
    "    dec : float\n",
    "        Déclinaison du centre du champ (degrés)\n",
    "    focal_length : float\n",
    "        Longueur focale de l'instrument (mm)\n",
    "    sensor_size : float\n",
    "        Taille du pixel du capteur (μm)\n",
    "    image_width : int\n",
    "        Largeur de l'image en pixels\n",
    "    mag_limit : float, optional\n",
    "        Magnitude limite en bande Rp (default: 19.5)\n",
    "    bp_rp_min : float, optional\n",
    "        Limite inférieure de l'indice de couleur BP-RP (default: -0.3)\n",
    "    bp_rp_max : float, optional\n",
    "        Limite supérieure de l'indice de couleur BP-RP (default: 0.9)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Table or None\n",
    "        Table Astropy contenant les résultats ou None en cas d'erreur\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Utilise la plate-scale pour calculer le rayon de recherche\n",
    "    - Exclut les étoiles variables\n",
    "    - Filtre sur la magnitude Rp et l'indice de couleur BP-RP\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calcul du champ de vue en arcminutes\n",
    "        plate_scale = 206.265 * sensor_size / focal_length  # arcsec/pixel\n",
    "        radius = (plate_scale * image_width) / 120  # conversion en arcminutes\n",
    "        \n",
    "        logger.info(f\"Recherche GAIA DR3 - rayon: {radius:.2f} arcmin - centre: RA={ra:.4f}°, Dec={dec:.4f}°\")\n",
    "\n",
    "        # Construction de la requête avec f-strings pour plus de clarté\n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            source_id, \n",
    "            ra, \n",
    "            dec, \n",
    "            phot_g_mean_mag,\n",
    "            phot_bp_mean_mag,\n",
    "            phot_rp_mean_mag,\n",
    "            bp_rp,\n",
    "            parallax,\n",
    "            pmra,\n",
    "            pmdec,\n",
    "            ruwe\n",
    "        FROM gaiadr3.gaia_source\n",
    "        WHERE 1 = CONTAINS(\n",
    "            POINT('ICRS', ra, dec),\n",
    "            CIRCLE('ICRS', {ra}, {dec}, {radius}/60.)\n",
    "        )\n",
    "        AND phot_rp_mean_mag < {mag_limit}\n",
    "        AND phot_variable_flag != 'VARIABLE'\n",
    "        AND phot_rp_mean_mag IS NOT NULL\n",
    "        AND bp_rp BETWEEN {bp_rp_min} AND {bp_rp_max}\n",
    "        AND ruwe < 1.4  # Filtre sur la qualité astrométrique\n",
    "        ORDER BY phot_rp_mean_mag ASC\n",
    "        \"\"\"\n",
    "\n",
    "        # Exécution de la requête avec gestion du timeout\n",
    "        job = Gaia.launch_job_async(query, timeout=300)\n",
    "        results = job.get_results()\n",
    "        \n",
    "        if len(results) == 0:\n",
    "            logger.warning(\"Aucune source trouvée dans le champ spécifié\")\n",
    "            return None\n",
    "            \n",
    "        logger.info(f\"Nombre de sources trouvées: {len(results)}\")\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de la requête Gaia: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19cc27f-5429-44be-878b-2d4a59368b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscale_image(data: np.ndarray, cmap: str = 'viridis') -> None:\n",
    "    \"\"\"\n",
    "    Affiche une image avec une échelle de couleur ajustée automatiquement en utilisant l'algorithme ZScaleInterval.\n",
    "\n",
    "    Cette fonction détermine automatiquement les limites de l'échelle de couleur à l'aide de l'algorithme\n",
    "    ZScaleInterval (couramment utilisé en astronomie), puis affiche l'image en utilisant la colormap spécifiée.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        Les données de l'image à afficher.\n",
    "    cmap : str, optionnel\n",
    "        Le nom de la colormap à utiliser pour l'affichage (par défaut 'viridis').\n",
    "\n",
    "    Retourne\n",
    "    --------\n",
    "    None\n",
    "        La fonction affiche l'image et n'a pas de valeur de retour.\n",
    "\n",
    "    Exemple\n",
    "    -------\n",
    "    >>> import numpy as np\n",
    "    >>> data = np.random.rand(100, 100)\n",
    "    >>> zscale_image(data, cmap='plasma')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialisation de l'algorithme ZScaleInterval pour déterminer les limites de l'échelle de couleur\n",
    "        norm = ZScaleInterval()\n",
    "        # Calcul des valeurs minimale et maximale pour l'échelle de couleur\n",
    "        vmin, vmax = norm.get_limits(data)\n",
    "        logger.info(f\"Valeurs calculées - vmin: {vmin}, vmax: {vmax}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors du calcul des limites de l'échelle de couleur avec ZScaleInterval: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Création de la figure et affichage de l'image avec la colormap spécifiée\n",
    "        plt.figure()\n",
    "        plt.imshow(\n",
    "            data,\n",
    "            vmin=vmin,        # Valeur minimale de l'échelle de couleur\n",
    "            vmax=vmax,        # Valeur maximale de l'échelle de couleur\n",
    "            origin='lower',   # Origine des coordonnées en bas à gauche\n",
    "            cmap=cmap         # Colormap utilisée pour l'affichage\n",
    "        )\n",
    "        plt.colorbar(aspect=8, shrink=0.75)  # Ajout d'une barre de couleur\n",
    "        logger.info(\"Affichage de l'image avec succès.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'affichage de l'image: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Affichage de l'image\n",
    "    try:\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'exécution de plt.show(): {e}\")\n",
    "        warnings.warn(\"Impossible d'afficher l'image avec plt.show().\", RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364693cd-e296-40ac-b52c-84d44e685bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histo_image(data: np.ndarray, cmap: str = 'viridis') -> None:\n",
    "    \"\"\"\n",
    "    Affiche une image en appliquant une normalisation et un étirement de l'histogramme.\n",
    "\n",
    "    Cette fonction normalise l'image à l'aide d'une normalisation basée sur MinMaxInterval et \n",
    "    applique un étirement de l'histogramme avec HistEqStretch pour mettre en valeur les détails \n",
    "    de l'image.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        Tableau contenant les données de l'image à afficher.\n",
    "    cmap : str, optionnel\n",
    "        Nom de la colormap utilisée pour l'affichage (par défaut 'viridis').\n",
    "\n",
    "    Retourne\n",
    "    --------\n",
    "    None\n",
    "        La fonction affiche l'image et ne retourne rien.\n",
    "\n",
    "    Exemple\n",
    "    -------\n",
    "    >>> import numpy as np\n",
    "    >>> data = np.random.rand(100, 100)\n",
    "    >>> histo_image(data, cmap='plasma')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialisation de la normalisation de l'image avec MinMaxInterval et HistEqStretch\n",
    "        norm = ImageNormalize(data, \n",
    "                              interval=MinMaxInterval(),  # Normalisation basée sur les valeurs min et max\n",
    "                              stretch=HistEqStretch())    # Étirement de l'histogramme égalisé\n",
    "        logger.info(\"Normalisation de l'image initialisée avec succès.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'initialisation de la normalisation de l'image: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Création de la figure et affichage de l'image avec la normalisation et la colormap spécifiées\n",
    "        plt.figure()\n",
    "        plt.imshow(data, \n",
    "                   norm=norm,        # Application de la normalisation à l'image\n",
    "                   origin='lower',   # Origine des coordonnées en bas à gauche\n",
    "                   cmap=cmap)        # Colormap utilisée pour l'affichage\n",
    "        plt.colorbar(aspect=8, shrink=0.75)  # Ajout d'une barre de couleur\n",
    "        logger.info(\"Affichage de l'image effectué avec succès.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'affichage de l'image: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'exécution de plt.show(): {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28690b8-fb7b-458a-ab61-a91e5fad9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def airmass(\n",
    "    head: Dict,\n",
    "    latitude: float = 48.29166,\n",
    "    longitude: float = 2.43805,\n",
    "    elevation: float = 95.0\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calcule la masse d'air pour un objet céleste à partir des informations contenues dans un header FITS.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    head : dict\n",
    "        Dictionnaire contenant les informations sur les coordonnées de l'objet céleste et la date d'observation.\n",
    "        Les clés attendues sont \"DATE-OBS\" et l'une de \"RA\" ou \"OBJRA\" pour l'ascension droite, et l'une de \"DEC\" ou \"OBJDEC\" pour la déclinaison.\n",
    "    latitude : float, optionnel\n",
    "        Latitude de l'observatoire en degrés (par défaut 48.29166).\n",
    "    longitude : float, optionnel\n",
    "        Longitude de l'observatoire en degrés (par défaut 2.43805).\n",
    "    elevation : float, optionnel\n",
    "        Élévation de l'observatoire en mètres (par défaut 95.0).\n",
    "\n",
    "    Retourne\n",
    "    --------\n",
    "    float\n",
    "        La masse d'air calculée. En cas d'erreur lors de l'extraction ou du calcul, retourne 0.0.\n",
    "\n",
    "    Exemple\n",
    "    -------\n",
    "    >>> head = {\n",
    "    ...     \"RA\": \"10:00:00\",\n",
    "    ...     \"DEC\": \"+10:00:00\",\n",
    "    ...     \"DATE-OBS\": \"2020-01-01T00:00:00\"\n",
    "    ... }\n",
    "    >>> am = airmass(head)\n",
    "    >>> print(am)\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    try:\n",
    "        # Extraction des coordonnées et du temps d'observation\n",
    "        ra = head.get(\"RA\", head.get(\"OBJRA\"))\n",
    "        dec = head.get(\"DEC\", head.get(\"OBJDEC\"))\n",
    "        obstime_str = head[\"DATE-OBS\"]\n",
    "\n",
    "        if ra is None or dec is None:\n",
    "            raise KeyError(\"Les informations RA/DEC ou OBJRA/OBJDEC sont manquantes dans le header.\")\n",
    "\n",
    "        # Conversion du temps d'observation en objet Time d'Astropy\n",
    "        obstime = Time(obstime_str)\n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Erreur lors de l'extraction des données du header: {e}\")\n",
    "        return 0.0\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur inattendue lors de la conversion des données du header: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "    try:\n",
    "        # Création de l'objet SkyCoord pour les coordonnées de l'objet\n",
    "        coord = SkyCoord(ra=ra, dec=dec, unit=u.deg, frame='icrs')\n",
    "\n",
    "        # Création de l'objet Observer pour représenter l'observatoire\n",
    "        observatory = Observer(latitude=latitude*u.deg, longitude=longitude*u.deg, elevation=elevation*u.m)\n",
    "\n",
    "        # Calcul des coordonnées alt-azimutales et de la masse d'air\n",
    "        altaz = observatory.altaz(obstime, coord)\n",
    "        am = altaz.secz\n",
    "\n",
    "        if am < 1:\n",
    "            logger.warning(\"La masse d'air est inférieure à 1, vérifiez les données d'entrée.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors du calcul de la masse d'air: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "    logger.info(f\"La masse d'air calculée est : {am}\")\n",
    "    return am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5ee0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_quality(\n",
    "    data: np.ndarray,\n",
    "    im_wcs: WCS,\n",
    "    sigma: float = 3.0,\n",
    "    seeing: float = 3.0\n",
    ") -> Tuple[float, float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Évalue la qualité d'une image astronomique en calculant des statistiques de base \n",
    "    et en estimant la largeur à mi-hauteur (FWHM).\n",
    "\n",
    "    Cette fonction effectue les opérations suivantes :\n",
    "      - Affichage des valeurs minimale et maximale en ADU.\n",
    "      - Calcul des statistiques de base (moyenne, médiane, écart-type) après sigma-clipping.\n",
    "      - Calcul de l'échelle des pixels en arcsecondes à partir du WCS.\n",
    "      - Estimation de la FWHM en pixels à partir du seeing (en arcsecondes).\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        Tableau contenant les données de l'image.\n",
    "    im_wcs : WCS\n",
    "        Objet WCS (World Coordinate System) associé à l'image.\n",
    "    sigma : float, optionnel\n",
    "        Facteur de sigma utilisé pour le sigma-clipping lors du calcul des statistiques (par défaut 3.0).\n",
    "    seeing : float, optionnel\n",
    "        Valeur du seeing en arcsecondes pour estimer la FWHM (par défaut 3.0).\n",
    "\n",
    "    Retourne\n",
    "    --------\n",
    "    Tuple[float, float, float, float, float]\n",
    "        Un tuple contenant :\n",
    "          - mean : Moyenne des données après sigma-clipping (en ADU).\n",
    "          - median : Médiane des données après sigma-clipping (en ADU).\n",
    "          - std : Écart-type des données après sigma-clipping (en ADU).\n",
    "          - fwhm : Estimation de la FWHM en pixels.\n",
    "          - pixel_scale : Échelle des pixels en arcsecondes.\n",
    "\n",
    "    Exemple\n",
    "    -------\n",
    "    >>> from astropy.wcs import WCS\n",
    "    >>> import numpy as np\n",
    "    >>> # Création d'une image factice et d'un WCS fictif\n",
    "    >>> data = np.random.normal(loc=1000, scale=50, size=(1024, 1024))\n",
    "    >>> wcs_header = {\n",
    "    ...     'CTYPE1': 'RA---TAN',\n",
    "    ...     'CTYPE2': 'DEC--TAN',\n",
    "    ...     'CRVAL1': 0,\n",
    "    ...     'CRVAL2': 0,\n",
    "    ...     'CRPIX1': 512,\n",
    "    ...     'CRPIX2': 512,\n",
    "    ...     'CD1_1': -0.0002777777778,\n",
    "    ...     'CD1_2': 0,\n",
    "    ...     'CD2_1': 0,\n",
    "    ...     'CD2_2': 0.0002777777778\n",
    "    ... }\n",
    "    >>> im_wcs = WCS(wcs_header)\n",
    "    >>> stats = image_quality(data, im_wcs, sigma=3.0, seeing=3.0)\n",
    "    >>> print(stats)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Affichage des valeurs min et max en ADU via logging\n",
    "        min_val = np.min(data)\n",
    "        max_val = np.max(data)\n",
    "        logger.info(f\"Valeur minimale: {min_val} ADU\")\n",
    "        logger.info(f\"Valeur maximale: {max_val} ADU\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors du calcul des valeurs min/max: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Calcul des statistiques après sigma-clipping\n",
    "        mean, median, std = sigma_clipped_stats(data, sigma=sigma)\n",
    "        logger.info(f\"Mean après sigma-clipping: {mean} ADU\")\n",
    "        logger.info(f\"Median après sigma-clipping: {median} ADU\")\n",
    "        logger.info(f\"StD après sigma-clipping: {std} ADU\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors du calcul des statistiques sigma-clipped: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Calcul de l'échelle des pixels en arcsecondes à partir du WCS\n",
    "        scales_deg = wcs_utils.proj_plane_pixel_scales(im_wcs)\n",
    "        pixel_scale = np.median(scales_deg) * u.deg.to(u.arcsec)\n",
    "        logger.info(f\"Pixel Scale: {round(pixel_scale, 2)} arcsec\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'extraction de l'échelle du WCS: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Estimation de la FWHM en pixels à partir du seeing (en arcsec)\n",
    "        fwhm = (seeing * u.arcsec) / pixel_scale\n",
    "        fwhm_pixels = round(fwhm.value, 2)\n",
    "        logger.info(f\"FWHM estimée: {fwhm_pixels} pixels\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors du calcul de la FWHM: {e}\")\n",
    "        raise\n",
    "\n",
    "    return mean, median, std, fwhm_pixels, round(pixel_scale, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd03fa69-7b5f-4a02-8c6a-1343a46e28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fits(\n",
    "    file_path: Union[str, Path], \n",
    "    extension: int = 0,\n",
    "    validate_wcs: bool = True,\n",
    "    ignore_missing_wcs: bool = False\n",
    ") -> Tuple[fits.Header, np.ndarray, Optional[WCS]]:\n",
    "    \"\"\"\n",
    "    Charge et valide un fichier FITS astronomique.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str or Path\n",
    "        Chemin vers le fichier FITS\n",
    "    extension : int, optional\n",
    "        Index de l'extension FITS à charger (default: 0)\n",
    "    validate_wcs : bool, optional\n",
    "        Valider la cohérence du WCS si présent (default: True)\n",
    "    ignore_missing_wcs : bool, optional\n",
    "        Ne pas lever d'avertissement si le WCS est absent (default: False)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    header : fits.Header\n",
    "        En-tête FITS de l'extension spécifiée\n",
    "    data : np.ndarray\n",
    "        Données de l'image\n",
    "    wcs : WCS or None\n",
    "        Objet WCS si les informations astrométriques sont valides, None sinon\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    FileNotFoundError\n",
    "        Si le fichier n'existe pas\n",
    "    IOError\n",
    "        Si le fichier n'est pas un FITS valide\n",
    "    ValueError\n",
    "        Si l'extension demandée n'existe pas\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - Vérifie la présence et la validité des informations WCS\n",
    "    - Gère les cas particuliers (données vides, WCS invalide)\n",
    "    - Effectue des validations basiques sur les données\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_path = Path(file_path)\n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"Le fichier {file_path} n'existe pas\")\n",
    "\n",
    "        # Suppression des warnings Astropy non critiques\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore', category=AstropyWarning)\n",
    "            \n",
    "            with fits.open(file_path) as hdul:\n",
    "                # Vérification de l'extension\n",
    "                if extension >= len(hdul):\n",
    "                    raise ValueError(f\"Extension {extension} invalide. Max: {len(hdul)-1}\")\n",
    "                \n",
    "                # Extraction des données et du header\n",
    "                hdu = hdul[extension]\n",
    "                header = hdu.header.copy()  # Copie pour éviter les problèmes de référence\n",
    "                data = hdu.data.copy()\n",
    "\n",
    "                # Validation basique des données\n",
    "                if data is None:\n",
    "                    raise ValueError(\"L'extension ne contient pas de données\")\n",
    "                \n",
    "                if not isinstance(data, np.ndarray):\n",
    "                    raise ValueError(\"Les données ne sont pas dans un format valide\")\n",
    "\n",
    "                # Vérification du WCS\n",
    "                wcs_info = None\n",
    "                required_wcs_keys = {\n",
    "                    'CTYPE1', 'CTYPE2', 'CRVAL1', 'CRVAL2',\n",
    "                    'CRPIX1', 'CRPIX2'\n",
    "                }\n",
    "                \n",
    "                if all(key in header for key in required_wcs_keys):\n",
    "                    try:\n",
    "                        wcs_info = WCS(header)\n",
    "                        \n",
    "                        if validate_wcs:\n",
    "                            # Validation du WCS\n",
    "                            test_points = np.array([[0, 0], [data.shape[1]-1, data.shape[0]-1]])\n",
    "                            sky_coords = wcs_info.all_pix2world(test_points, 0)\n",
    "                            \n",
    "                            # Vérification des valeurs raisonnables\n",
    "                            if not (np.all(np.isfinite(sky_coords)) and \n",
    "                                  np.all((-90 <= sky_coords[:, 1]) & (sky_coords[:, 1] <= 90))):\n",
    "                                logger.warning(\"WCS détecté mais coordonnées invalides\")\n",
    "                                wcs_info = None\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"WCS détecté mais invalide: {str(e)}\")\n",
    "                        wcs_info = None\n",
    "                elif not ignore_missing_wcs:\n",
    "                    logger.warning(\"Pas d'information WCS dans le header\")\n",
    "\n",
    "                # Ajout d'informations statistiques au header\n",
    "                with np.errstate(invalid='ignore'):\n",
    "                    header['IMGMED'] = float(np.median(data))\n",
    "                    header['IMGMEAN'] = float(np.mean(data))\n",
    "                    header['IMGSTD'] = float(np.std(data))\n",
    "                    header['IMGMIN'] = float(np.min(data))\n",
    "                    header['IMGMAX'] = float(np.max(data))\n",
    "\n",
    "                return header, data, wcs_info\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors du chargement du fichier {file_path}: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def is_calibration_frame(header: fits.Header) -> bool:\n",
    "    \"\"\"\n",
    "    Détecte si l'image est une frame de calibration (bias, dark, flat).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    header : fits.Header\n",
    "        Header FITS à analyser\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True si c'est une frame de calibration\n",
    "    \"\"\"\n",
    "    # Mots-clés communs pour les frames de calibration\n",
    "    calibration_keywords = ['BIAS', 'DARK', 'FLAT', 'SKYFLAT', 'DOMEFLAT']\n",
    "    \n",
    "    # Vérifie dans les mots-clés IMAGETYP, OBSTYPE, etc.\n",
    "    for key in ['IMAGETYP', 'OBSTYPE', 'FRAME']:\n",
    "        if key in header:\n",
    "            value = header[key].upper()\n",
    "            if any(cal_type in value for cal_type in calibration_keywords):\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# try:\n",
    "#     # Chargement d'une image\n",
    "#     header, data, wcs = load_fits(\n",
    "#         \"mon_image.fits\",\n",
    "#         extension=0,\n",
    "#         validate_wcs=True\n",
    "#     )\n",
    "    \n",
    "#     # Vérification si c'est une frame de calibration\n",
    "#     if is_calibration_frame(header):\n",
    "#         logger.info(\"Image de calibration détectée\")\n",
    "        \n",
    "#     # Utilisation des statistiques\n",
    "#     print(f\"Médiane de l'image: {header['IMGMED']}\")\n",
    "#     print(f\"Écart-type: {header['IMGSTD']}\")\n",
    "    \n",
    "#     if wcs is not None:\n",
    "#         # Conversion de coordonnées avec le WCS\n",
    "#         ra, dec = wcs.all_pix2world(100, 100, 0)\n",
    "#         print(f\"Coordonnées du pixel (100,100): RA={ra}, Dec={dec}\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     logger.error(f\"Erreur: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad58f3-8ca6-4e82-ad40-f54e9063f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_background(\n",
    "    img: np.ndarray,\n",
    "    sigma: float = 3.0,\n",
    "    box_size: Tuple[int, int] = (100, 100),\n",
    "    filter_size: Tuple[int, int] = (5, 5),\n",
    "    mask: Optional[np.ndarray] = None,\n",
    "    exclude_percentile: float = 25.0\n",
    ") -> Background2D:\n",
    "    \"\"\"\n",
    "    Calcule le fond de ciel d'une image en utilisant la méthode `Background2D` de `photutils`.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    img : np.ndarray\n",
    "        Image pour laquelle le fond de ciel doit être estimé.\n",
    "    sigma : float, optionnel\n",
    "        Seuil en sigma pour le sigma-clipping (par défaut 3.0).\n",
    "    box_size : tuple de int, optionnel\n",
    "        Taille de la boîte (en pixels) pour le calcul local du fond de ciel (par défaut (100, 100)).\n",
    "    filter_size : tuple de int, optionnel\n",
    "        Taille du filtre pour lisser le fond de ciel (par défaut (5, 5)).\n",
    "    mask : np.ndarray, optionnel\n",
    "        Masque binaire où les pixels masqués sont exclus du calcul du fond de ciel.\n",
    "    exclude_percentile : float, optionnel\n",
    "        Pourcentage d'exclusion utilisé par Background2D pour éviter l'influence d'outliers (par défaut 25.0).\n",
    "\n",
    "    Retourne\n",
    "    --------\n",
    "    Background2D\n",
    "        Objet contenant le fond de ciel estimé et la carte du bruit.\n",
    "\n",
    "    Exemple\n",
    "    -------\n",
    "    >>> from photutils import Background2D\n",
    "    >>> background = compute_background(image_data, sigma=3.0, box_size=(100, 100))\n",
    "    >>> bkg_image = background.background\n",
    "    \"\"\"\n",
    "    # Créer l'objet SigmaClip pour exclure les valeurs aberrantes\n",
    "    sigma_clip = SigmaClip(sigma=sigma)\n",
    "\n",
    "    # Créer l'estimateur du fond de ciel basé sur SExtractor\n",
    "    bkg_estimator = SExtractorBackground()\n",
    "\n",
    "    try:\n",
    "        bkg = Background2D(\n",
    "            data=img,\n",
    "            box_size=box_size,\n",
    "            filter_size=filter_size,\n",
    "            mask=mask,\n",
    "            sigma_clip=sigma_clip,\n",
    "            bkg_estimator=bkg_estimator,\n",
    "            exclude_percentile=exclude_percentile\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\"Erreur lors du calcul du fond de ciel\") from e\n",
    "\n",
    "    return bkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8a1b2e-19ec-4d1b-aaa0-8b5bedf7e8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_border_mask(\n",
    "    image: np.ndarray,\n",
    "    border: Union[int, Tuple[int, int], Tuple[int, int, int, int]] = 50,\n",
    "    invert: bool = True,\n",
    "    dtype: np.dtype = bool\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Crée un masque binaire pour une image en excluant une ou plusieurs bordures.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.ndarray\n",
    "        Image source pour laquelle le masque doit être créé\n",
    "    border : int or tuple, optional\n",
    "        Peut être :\n",
    "        - int : même largeur pour toutes les bordures\n",
    "        - tuple[int, int] : (vertical, horizontal)\n",
    "        - tuple[int, int, int, int] : (haut, bas, gauche, droite)\n",
    "        (default: 50)\n",
    "    invert : bool, optional\n",
    "        Si True, inverse le masque (bordure = True, centre = False)\n",
    "        Si False, bordure = False, centre = True\n",
    "        (default: True)\n",
    "    dtype : np.dtype, optional\n",
    "        Type de données du masque de sortie (default: bool)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Masque binaire de la même taille que l'image\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        Si les dimensions de la bordure sont invalides ou trop grandes\n",
    "    TypeError\n",
    "        Si les types d'entrée sont incorrects\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Masque avec bordure uniforme de 50 pixels\n",
    "    >>> mask = make_border_mask(image, 50)\n",
    "    \n",
    "    >>> # Masque avec bordures différentes (haut, bas, gauche, droite)\n",
    "    >>> mask = make_border_mask(image, (100, 50, 75, 75))\n",
    "    \n",
    "    >>> # Masque non inversé (True au centre)\n",
    "    >>> mask = make_border_mask(image, 50, invert=False)\n",
    "    \"\"\"\n",
    "    # Validation du type d'entrée\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        raise TypeError(\"L'image doit être un numpy.ndarray\")\n",
    "    \n",
    "    if image.size == 0:\n",
    "        raise ValueError(\"L'image ne peut pas être vide\")\n",
    "\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Conversion et validation des bordures\n",
    "    if isinstance(border, (int, float)):\n",
    "        border = int(border)\n",
    "        top = bottom = left = right = border\n",
    "    elif isinstance(border, tuple):\n",
    "        if len(border) == 2:\n",
    "            vert, horiz = border\n",
    "            top = bottom = vert\n",
    "            left = right = horiz\n",
    "        elif len(border) == 4:\n",
    "            top, bottom, left, right = border\n",
    "        else:\n",
    "            raise ValueError(\"border doit être un int ou un tuple de 2 ou 4 éléments\")\n",
    "    else:\n",
    "        raise TypeError(\"border doit être un int ou un tuple\")\n",
    "\n",
    "    # Validation des dimensions\n",
    "    if any(b < 0 for b in (top, bottom, left, right)):\n",
    "        raise ValueError(\"Les bordures ne peuvent pas être négatives\")\n",
    "    \n",
    "    if top + bottom >= height or left + right >= width:\n",
    "        raise ValueError(\"Les bordures sont plus grandes que l'image\")\n",
    "\n",
    "    # Création du masque\n",
    "    mask = np.zeros(image.shape[:2], dtype=dtype)\n",
    "    mask[top:height-bottom, left:width-right] = True\n",
    "\n",
    "    return ~mask if invert else mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ace729c-70b1-40cf-9c95-5c49921da40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwhm_fit(\n",
    "    img: np.ndarray,\n",
    "    sources: Table,\n",
    "    fwhm: float,\n",
    "    pixel_scale: float,\n",
    "    std_lo: float = 0.5,\n",
    "    std_hi: float = 0.5\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calcule la largeur à mi-hauteur (FWHM) d'une image en ajustant un modèle gaussien aux sources détectées.\n",
    "    \n",
    "    Cette fonction filtre d'abord les sources en fonction de leur flux, en gardant celles dont le flux est \n",
    "    situé dans une plage définie par les paramètres `std_lo` et `std_hi` autour de la médiane. Pour chaque \n",
    "    source filtrée, une sous-image est extraite et un ajustement d'un modèle gaussien 1D est réalisé sur la \n",
    "    distribution radiale du flux. La FWHM est alors calculée via la relation FWHM = 2.355 * stddev, convertie en \n",
    "    pixels à l'aide de `pixel_scale`.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    img : np.ndarray\n",
    "        Image dans laquelle les sources ont été détectées.\n",
    "    sources : Table\n",
    "        Table contenant les positions et les flux des sources détectées. Les colonnes attendues sont :\n",
    "        - 'flux' : flux total ou une mesure associée à la source.\n",
    "        - 'xcentroid' : position X de la source.\n",
    "        - 'ycentroid' : position Y de la source.\n",
    "        - 'peak' : flux de pic de la source.\n",
    "    fwhm : float\n",
    "        Estimation initiale de la FWHM pour l'ajustement.\n",
    "    pixel_scale : float\n",
    "        Échelle en pixels pour la conversion des distances.\n",
    "    std_lo : float, optionnel\n",
    "        Seuil inférieur (en écart-type) pour filtrer les sources (par défaut 1.5).\n",
    "    std_hi : float, optionnel\n",
    "        Seuil supérieur (en écart-type) pour filtrer les sources (par défaut 2.0).\n",
    "    \n",
    "    Retourne\n",
    "    --------\n",
    "    float\n",
    "        FWHM médiane estimée en pixels, basée sur l'ajustement du modèle gaussien aux sources filtrées.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Filtrage des sources en fonction du flux\n",
    "        flux = sources['flux']\n",
    "        median_flux = np.median(flux)\n",
    "        std_flux = np.std(flux)\n",
    "        mask = (flux > median_flux + std_lo * std_flux) & (flux < median_flux + std_hi * std_flux)\n",
    "        filtered_sources = sources[mask]\n",
    "        \n",
    "        # Suppression des sources contenant des valeurs NaN dans le flux\n",
    "        filtered_sources = filtered_sources[~np.isnan(filtered_sources['flux'])]\n",
    "        \n",
    "        logger.info(f\"Nombre de sources après filtrage: {len(filtered_sources)}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors du filtrage des sources: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Initialisation du fitter\n",
    "    fitter = fitting.SimplexLSQFitter()\n",
    "\n",
    "    # Définition du rayon d'analyse (en pixels)\n",
    "    analysis_radius = 3 * round(fwhm)\n",
    "    fwhm_values = []\n",
    "\n",
    "    # Ajustement du modèle pour chaque source filtrée\n",
    "    for source in filtered_sources:\n",
    "        try:\n",
    "            x_cen = source['xcentroid']\n",
    "            y_cen = source['ycentroid']\n",
    "            peak = source['peak']\n",
    "\n",
    "            # Définir les limites de la sous-image\n",
    "            x_start, x_end = int(x_cen) - analysis_radius, int(x_cen) + analysis_radius\n",
    "            y_start, y_end = int(y_cen) - analysis_radius, int(y_cen) + analysis_radius\n",
    "\n",
    "            # Extraction de la sous-image\n",
    "            sub_img = img[y_start:y_end, x_start:x_end]\n",
    "            if sub_img.size == 0:\n",
    "                logger.warning(\"Sous-image vide pour une source; passage à la suivante.\")\n",
    "                continue\n",
    "\n",
    "            # Génération des grilles de coordonnées pour l'ajustement\n",
    "            x_grid, y_grid = np.meshgrid(np.arange(x_start, x_end), np.arange(y_start, y_end))\n",
    "\n",
    "            # Calcul des distances en pixels par rapport au centre de la source\n",
    "            distances = np.sqrt((x_grid - x_cen) ** 2 + (y_grid - y_cen) ** 2).ravel()\n",
    "\n",
    "            # Calcul des flux normalisés par le pic de la source\n",
    "            flux_counts = (sub_img / peak).ravel()\n",
    "\n",
    "            # Ajustement du modèle Gaussien\n",
    "            gauss_model = models.Gaussian1D(amplitude=1.0, mean=0, stddev=fwhm)\n",
    "            fitted_gauss = fitter(gauss_model, distances, flux_counts)\n",
    "\n",
    "            # Calcul de la FWHM en pixels\n",
    "            fwhm_gauss = 2.355 * fitted_gauss.stddev * pixel_scale\n",
    "            fwhm_values.append(fwhm_gauss)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erreur lors de l'ajustement pour la source aux coordonnées \"\n",
    "                         f\"({x_cen}, {y_cen}): {e}\")\n",
    "            continue\n",
    "\n",
    "    if len(fwhm_values) == 0:\n",
    "        msg = \"Aucune source valide pour l'ajustement a été trouvée.\"\n",
    "        logger.error(msg)\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # Conversion de la liste en array pour filtrer les NaN et valeurs infinies\n",
    "    fwhm_values_arr = np.array(fwhm_values)\n",
    "    # Filtrer les valeurs non numériques ou infinies\n",
    "    valid = ~np.isnan(fwhm_values_arr) & ~np.isinf(fwhm_values_arr)\n",
    "    if not np.any(valid):\n",
    "        msg = \"Toutes les valeurs de FWHM sont NaN ou infinies.\"\n",
    "        logger.error(msg)\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    mean_fwhm = np.median(fwhm_values_arr[valid])\n",
    "    logger.info(f\"Estimation médiane de la FWHM basée sur le modèle Gaussien: {round(mean_fwhm)} pixels\")\n",
    "    \n",
    "    return round(mean_fwhm)\n",
    "\n",
    "# if fitter.fit_info['final_func_val'] < 5.0:\n",
    "#     color = 'green'\n",
    "# else:\n",
    "#     color = 'red'\n",
    "    \n",
    "# # Plot the data with the best-fit model\n",
    "# plt.figure()\n",
    "# plt.plot(pixel_distance, flux_counts, 'ko')\n",
    "# rx = np.linspace(0, int(max(pixel_distance)), int(max(pixel_distance)) * 10)\n",
    "# plt.plot(rx,\n",
    "#          fitted_model(rx),\n",
    "#          color=color,\n",
    "#          lw=3.0,\n",
    "#          label='SN: %.2f, Fit: %.2f, FWHM: %.2f\"' % (isource['flux'] * sigma,\n",
    "#                                                      fitter.fit_info['final_func_val'],\n",
    "#                                                      f.value * pixel_scale.value))\n",
    "# plt.xlabel('Distance (pixels)')\n",
    "# plt.ylabel('Normalized flux (ADU)')\n",
    "# plt.title('%s profile fit' % model)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b364e6-e4b7-4a2d-8efc-c4ce7dbab997",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BackgroundStats:\n",
    "    \"\"\"Statistiques du fond de ciel.\"\"\"\n",
    "    mean: float\n",
    "    median: float\n",
    "    std: float\n",
    "    rms: float\n",
    "    global_background: float\n",
    "    global_rms: float\n",
    "\n",
    "class BackgroundResult(NamedTuple):\n",
    "    \"\"\"Résultats de la soustraction du fond.\"\"\"\n",
    "    subtracted_data: np.ndarray\n",
    "    background_map: np.ndarray\n",
    "    rms_map: np.ndarray\n",
    "    stats: BackgroundStats\n",
    "    background_obj: sep.Background\n",
    "\n",
    "def estimate_background(\n",
    "    data: np.ndarray,\n",
    "    mask: Optional[np.ndarray] = None,\n",
    "    box_size: Union[int, Tuple[int, int]] = 64,\n",
    "    filter_size: Union[int, Tuple[int, int]] = 3,\n",
    "    filter_threshold: float = 0.0,\n",
    "    sigma_clip: bool = True,\n",
    "    n_sigma: float = 3.0,\n",
    "    return_stats: bool = True\n",
    ") -> BackgroundResult:\n",
    "    \"\"\"\n",
    "    Estime et soustrait le fond de ciel d'une image astronomique.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        Image 2D à traiter\n",
    "    mask : np.ndarray, optional\n",
    "        Masque binaire (True = pixels à ignorer)\n",
    "    box_size : int or tuple, optional\n",
    "        Taille de la boîte pour l'estimation du fond\n",
    "        - int : même taille en x et y\n",
    "        - tuple : (size_y, size_x)\n",
    "        (default: 64)\n",
    "    filter_size : int or tuple, optional\n",
    "        Taille du filtre de lissage\n",
    "        - int : même taille en x et y\n",
    "        - tuple : (size_y, size_x)\n",
    "        (default: 3)\n",
    "    filter_threshold : float, optional\n",
    "        Seuil de filtrage (default: 0.0)\n",
    "    sigma_clip : bool, optional\n",
    "        Utiliser sigma clipping pour les statistiques (default: True)\n",
    "    n_sigma : float, optional\n",
    "        Nombre de sigma pour le clipping (default: 3.0)\n",
    "    return_stats : bool, optional\n",
    "        Calculer et retourner les statistiques détaillées (default: True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    BackgroundResult\n",
    "        Named tuple contenant:\n",
    "        - subtracted_data : Image avec fond soustrait\n",
    "        - background_map : Carte du fond\n",
    "        - rms_map : Carte du bruit RMS\n",
    "        - stats : Statistiques du fond\n",
    "        - background_obj : Objet sep.Background\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        Si les dimensions ou paramètres sont invalides\n",
    "    TypeError\n",
    "        Si les types d'entrée sont incorrects\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Utilise SEP pour l'estimation du fond\n",
    "    - Applique optionnellement sigma clipping pour les statistiques\n",
    "    - Gère automatiquement la conversion en float32 si nécessaire\n",
    "    \"\"\"\n",
    "    # Validation des entrées\n",
    "    if not isinstance(data, np.ndarray) or data.ndim != 2:\n",
    "        raise ValueError(\"data doit être un tableau numpy 2D\")\n",
    "    \n",
    "    # Conversion en float32 si nécessaire (requis par sep)\n",
    "    if data.dtype != np.float32:\n",
    "        data = data.astype(np.float32)\n",
    "    \n",
    "    # Gestion des tailles de boîte et de filtre\n",
    "    if isinstance(box_size, int):\n",
    "        bh, bw = box_size, box_size\n",
    "    else:\n",
    "        bh, bw = box_size\n",
    "        \n",
    "    if isinstance(filter_size, int):\n",
    "        fh, fw = filter_size, filter_size\n",
    "    else:\n",
    "        fh, fw = filter_size\n",
    "        \n",
    "    # Validation des dimensions\n",
    "    if any(s <= 0 for s in [bh, bw, fh, fw]):\n",
    "        raise ValueError(\"Les tailles doivent être positives\")\n",
    "    if any(s > min(data.shape) for s in [bh, bw]):\n",
    "        raise ValueError(\"Taille de boîte trop grande pour l'image\")\n",
    "        \n",
    "    try:\n",
    "        # Estimation du fond avec SEP\n",
    "        bkg = sep.Background(\n",
    "            data,\n",
    "            mask=mask,\n",
    "            bw=bw,\n",
    "            bh=bh,\n",
    "            fw=fw,\n",
    "            fh=fh,\n",
    "            fthresh=filter_threshold\n",
    "        )\n",
    "        \n",
    "        # Création des cartes\n",
    "        bkg_map = bkg.back()\n",
    "        rms_map = bkg.rms()\n",
    "        \n",
    "        # Soustraction du fond\n",
    "        data_sub = data - bkg_map\n",
    "        \n",
    "        # Calcul des statistiques détaillées si demandé\n",
    "        if return_stats:\n",
    "            if sigma_clip:\n",
    "                mean, median, std = sigma_clipped_stats(\n",
    "                    data_sub,\n",
    "                    sigma=n_sigma,\n",
    "                    mask=mask\n",
    "                )\n",
    "            else:\n",
    "                if mask is not None:\n",
    "                    valid_data = data_sub[~mask]\n",
    "                else:\n",
    "                    valid_data = data_sub\n",
    "                mean = np.mean(valid_data)\n",
    "                median = np.median(valid_data)\n",
    "                std = np.std(valid_data)\n",
    "            \n",
    "            stats = BackgroundStats(\n",
    "                mean=float(mean),\n",
    "                median=float(median),\n",
    "                std=float(std),\n",
    "                rms=float(np.median(rms_map)),\n",
    "                global_background=float(np.median(bkg_map)),\n",
    "                global_rms=float(np.std(bkg_map))\n",
    "            )\n",
    "        else:\n",
    "            stats = None\n",
    "        \n",
    "        return BackgroundResult(\n",
    "            subtracted_data=data_sub,\n",
    "            background_map=bkg_map,\n",
    "            rms_map=rms_map,\n",
    "            stats=stats,\n",
    "            background_obj=bkg\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'estimation du fond: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def estimate_background_mesh(\n",
    "    data: np.ndarray,\n",
    "    box_size: int = 64,\n",
    "    threshold: Optional[float] = None\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Estimation rapide du fond utilisant une approche par grille.\n",
    "    Utile pour les estimations préliminaires.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        Image 2D\n",
    "    box_size : int, optional\n",
    "        Taille des boîtes de la grille (default: 64)\n",
    "    threshold : float, optional\n",
    "        Seuil pour le rejet des sources (default: None)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Carte du fond estimé\n",
    "    \"\"\"\n",
    "    h, w = data.shape\n",
    "    ny = h // box_size\n",
    "    nx = w // box_size\n",
    "    \n",
    "    # Création de la grille\n",
    "    mesh = data[:ny*box_size, :nx*box_size].reshape(ny, box_size, nx, box_size)\n",
    "    \n",
    "    # Calcul des médianes par boîte\n",
    "    if threshold is not None:\n",
    "        # Avec rejet des sources\n",
    "        mesh_values = np.ma.masked_greater(mesh, threshold)\n",
    "        background = np.ma.median(mesh_values, axis=(1,3))\n",
    "    else:\n",
    "        # Sans rejet\n",
    "        background = np.median(mesh, axis=(1,3))\n",
    "    \n",
    "    # Interpolation pour revenir à la taille originale\n",
    "    from scipy.ndimage import zoom\n",
    "    zoom_factor = (h/background.shape[0], w/background.shape[1])\n",
    "    background = zoom(background, zoom_factor, order=1)\n",
    "    \n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edae204a-515b-462f-9bcb-ca46b6d590b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2img(img1, img2, vmin, vmax, figsize=(9, 6), titles=['fig1', 'fig2'], cmap='viridis'):\n",
    "    \"\"\"\n",
    "    Affiche deux images côte à côte avec les mêmes échelles de couleur et un titre pour chaque image.\n",
    "\n",
    "    Paramètres :\n",
    "    img1 (ndarray): La première image à afficher.\n",
    "    img2 (ndarray): La deuxième image à afficher.\n",
    "    vmin (np.float): Valeur minimale pour l'échelle de couleur des images.\n",
    "    vmax (np.float): Valeur maximale pour l'échelle de couleur des images.\n",
    "    figsize (tuple, optionnel): Taille de la figure (largeur, hauteur) en pouces (par défaut (9, 6)).\n",
    "    titles (list, optionnel): Titres pour les deux images (par défaut ['fig1', 'fig2']).\n",
    "    cmap (str, optionnel): Colormap à utiliser pour l'affichage des images (par défaut 'viridis').\n",
    "\n",
    "    Retourne :\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Crée une figure avec la taille spécifiée\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "\n",
    "    # Affiche la première image dans le premier sous-plot\n",
    "    ax1 = plt.subplot(121)\n",
    "    ax1.imshow(img1, vmin=vmin, vmax=vmax, cmap=cmap, origin='lower')\n",
    "    ax1.set_title(titles[0])  # Définit le titre du premier sous-plot\n",
    "\n",
    "    # Affiche la deuxième image dans le deuxième sous-plot, partageant les axes avec le premier\n",
    "    ax2 = plt.subplot(122, sharex=ax1, sharey=ax1)\n",
    "    ax2.imshow(img2, vmin=vmin, vmax=vmax, cmap=cmap, origin='lower')\n",
    "    ax2.set_title(titles[1])  # Définit le titre du deuxième sous-plot\n",
    "\n",
    "    plt.tight_layout()  # Ajuste automatiquement les sous-plots pour éviter le chevauchement\n",
    "    _ = plt.show()  # Affiche la figure\n",
    "\n",
    "\n",
    "def pretty_print(table, precision=8):\n",
    "    \"\"\"\n",
    "    Formate et affiche une table avec une précision numérique spécifiée.\n",
    "\n",
    "    Paramètres :\n",
    "    table (astropy.table.Table): La table à afficher.\n",
    "    precision (int, optionnel): Nombre de chiffres significatifs pour les valeurs numériques (par défaut 8).\n",
    "\n",
    "    Retourne :\n",
    "    astropy.table.Table: La table formatée.\n",
    "    \"\"\"\n",
    "    # Définit le format d'affichage pour chaque colonne de la table\n",
    "    for col in table.colnames:\n",
    "        table[col].info.format = '%.{}g'.format(precision)  # Formatage pour une précision uniforme\n",
    "    \n",
    "    # Affiche la table avec les types de données visibles\n",
    "    table.pprint(show_dtype=True)\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea685837-8e69-4fb3-982f-6e3525a0c5d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_flux(\n",
    "    img: np.ndarray,\n",
    "    obj: np.ndarray,\n",
    "    img_sub: np.ndarray,\n",
    "    mask: Optional[np.ndarray] = None,\n",
    "    bg: Optional[Any] = None\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Mesure le flux et l'erreur associée pour une série d'objets détectés dans une image,\n",
    "    en utilisant la méthode du rayon de Kron et une extraction par ellipse. Les objets dont\n",
    "    l'aperture calculée dépasse les limites de l'image sont exclus.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    img : np.ndarray\n",
    "        Image complète utilisée pour calculer le rayon de Kron.\n",
    "    obj : np.ndarray\n",
    "        Tableau (ou tableau structuré) contenant les paramètres des objets détectés.\n",
    "        Doit contenir au minimum les colonnes suivantes :\n",
    "          - 'x' : coordonnée X de l'objet.\n",
    "          - 'y' : coordonnée Y de l'objet.\n",
    "          - 'a' : demi-grand axe de l'ellipse.\n",
    "          - 'b' : demi-petit axe de l'ellipse.\n",
    "          - 'theta' : angle de rotation de l'ellipse (en radians).\n",
    "    img_sub : np.ndarray\n",
    "        Sous-image sur laquelle le flux est mesuré (par exemple, une région découpée de l'image).\n",
    "    mask : np.ndarray, optionnel\n",
    "        Masque à appliquer lors du calcul du flux, afin d'exclure certains pixels.\n",
    "    bg : Any, optionnel\n",
    "        Objet contenant au moins l'attribut `globalrms` pour la gestion de l'erreur (par exemple,\n",
    "        le bruit de fond). Si `bg` est None, l'erreur ne sera pas prise en compte.\n",
    "\n",
    "    Retourne\n",
    "    --------\n",
    "    Tuple[np.ndarray, np.ndarray, np.ndarray]\n",
    "        - flux : Les flux mesurés pour chaque objet.\n",
    "        - fluxerr : Les erreurs associées aux flux mesurés.\n",
    "        - flag : Les indicateurs de qualité des mesures, combinant les flags de Kron et ceux \n",
    "          provenant de `sep.sum_ellipse`.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calcul du rayon de Kron pour chaque objet\n",
    "        kronrad, krflag = sep.kron_radius(\n",
    "            img,\n",
    "            obj['x'],\n",
    "            obj['y'],\n",
    "            obj['a'],\n",
    "            obj['b'],\n",
    "            obj['theta'],\n",
    "            6.0\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors du calcul du rayon de Kron: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Gestion des valeurs de rayon de Kron négatives ou nulles\n",
    "    if np.any(kronrad <= 0):\n",
    "        positive = kronrad > 0\n",
    "        if np.any(positive):\n",
    "            replacement = np.median(kronrad[positive])\n",
    "            kronrad[kronrad <= 0] = replacement\n",
    "            logger.info(\"Kronrad ajusté avec la médiane des valeurs positives.\")\n",
    "        else:\n",
    "            logger.error(\"Aucune valeur positive dans kronrad; impossible d'ajuster.\")\n",
    "            raise ValueError(\"Toutes les valeurs de kronrad sont <= 0.\")\n",
    "\n",
    "    logger.info(\"Kronrad ajusté.\")\n",
    "\n",
    "    # Détermination des dimensions de l'image\n",
    "    image_height, image_width = img.shape\n",
    "\n",
    "    # Vérification que les apertures restent dans les limites de l'image\n",
    "    valid_aperture = (\n",
    "        (obj['x'] + 2.5 * kronrad * obj['a'] < image_width) &\n",
    "        (obj['x'] - 2.5 * kronrad * obj['a'] >= 0) &\n",
    "        (obj['y'] + 2.5 * kronrad * obj['b'] < image_height) &\n",
    "        (obj['y'] - 2.5 * kronrad * obj['b'] >= 0)\n",
    "    )\n",
    "\n",
    "    if not np.all(valid_aperture):\n",
    "        logger.info(\"Certaines apertures sont hors des limites de l'image; elles seront exclues.\")\n",
    "        obj_flt = obj[valid_aperture]\n",
    "        kronrad_flt = kronrad[valid_aperture]\n",
    "        krflag_flt = krflag[valid_aperture]\n",
    "    else:\n",
    "        obj_flt = obj\n",
    "        kronrad_flt = kronrad\n",
    "        krflag_flt = krflag\n",
    "\n",
    "    try:\n",
    "        # Calcul du flux et des erreurs par ellipse\n",
    "        flux, fluxerr, flag = sep.sum_ellipse(\n",
    "            img_sub,\n",
    "            obj_flt['x'],\n",
    "            obj_flt['y'],\n",
    "            obj_flt['a'],\n",
    "            obj_flt['b'],\n",
    "            obj_flt['theta'],\n",
    "            2.5 * kronrad_flt,\n",
    "            mask=mask,\n",
    "            err=bg.globalrms if bg is not None else None\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors du calcul du flux par ellipse: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Combinaison des indicateurs de qualité\n",
    "    flag |= krflag_flt\n",
    "\n",
    "    return flux, fluxerr, flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f982e780-5dbf-47eb-a305-20425e725aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_psf_photometry(\n",
    "    img: np.ndarray,\n",
    "    phot_table: Table,\n",
    "    std_x: float,\n",
    "    std_y: float,\n",
    "    fwhm: float,\n",
    "    daostarfind: Callable\n",
    ") -> Tuple[Table, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Effectue une photométrie PSF sur une image donnée.\n",
    "\n",
    "    Cette fonction réalise la photométrie PSF en définissant un modèle PSF (ici un modèle gaussien 2D)\n",
    "    et en configurant une photométrie itérative. Elle utilise les positions initiales des sources issues de\n",
    "    `phot_table` et renvoie les résultats de la photométrie ainsi qu'une image résiduelle.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.ndarray\n",
    "        Image avec le fond de ciel soustrait.\n",
    "    phot_table : astropy.table.Table\n",
    "        Table contenant les positions initiales des sources. Doit contenir au moins les colonnes \n",
    "        'xcenter' et 'ycenter'.\n",
    "    std_x : float\n",
    "        Écart-type en x pour le modèle Gaussian2D.\n",
    "    std_y : float\n",
    "        Écart-type en y pour le modèle Gaussian2D.\n",
    "    fwhm : float\n",
    "        Full Width at Half Maximum servant à définir la taille de l'ajustement.\n",
    "    daostarfind : callable\n",
    "        Fonction de détection des étoiles à utiliser comme \"finder\" dans la photométrie PSF.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[astropy.table.Table, np.ndarray]\n",
    "        - phot : Résultats de la photométrie PSF sous forme de table.\n",
    "        - resid : Image des résidus après ajustement du modèle PSF.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Définir le modèle PSF (ici un modèle gaussien 2D)\n",
    "        model = models.Gaussian2D(amplitude=1, x_stddev=std_x, y_stddev=std_y)\n",
    "        # Vous pouvez aussi utiliser un modèle de type Moffat2D en décommentant la ligne suivante :\n",
    "        # model = models.Moffat2D(gamma=..., alpha=...)\n",
    "        psf_model = make_psf_model(model, use_dblquad=True)\n",
    "        logger.info(\"Modèle PSF initialisé avec succès.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'initialisation du modèle PSF: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Définir la forme de l'ajustement (taille de la boîte d'ajustement)\n",
    "        fit_shape = 2 * round(fwhm) + 1\n",
    "        logger.info(f\"Forme de l'ajustement définie: {fit_shape} pixels\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors du calcul de la forme de l'ajustement: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Configurer la photométrie PSF itérative\n",
    "        psfphot = IterativePSFPhotometry(\n",
    "            psf_model,\n",
    "            fit_shape,\n",
    "            finder=daostarfind,\n",
    "            aperture_radius=fit_shape / 2,\n",
    "            progress_bar=True,\n",
    "            fitter=fitting.LMLSQFitter()\n",
    "        )\n",
    "        logger.info(\"Photométrie PSF configurée avec succès.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de la configuration de la photométrie PSF: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Spécifier les positions initiales des sources à partir de la table\n",
    "        psfphot.x = phot_table['xcenter']\n",
    "        psfphot.y = phot_table['ycenter']\n",
    "        logger.info(\"Positions initiales des sources définies.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de la définition des positions des sources: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Création d'un masque pour les pixels non finis\n",
    "        mask = ~np.isfinite(img)\n",
    "        # Exécuter la photométrie PSF sur l'image\n",
    "        phot = psfphot(img, mask=mask)\n",
    "        logger.info(\"Photométrie PSF exécutée avec succès.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'exécution de la photométrie PSF: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Calculer l'image résiduelle (différence entre l'image et le modèle PSF ajusté)\n",
    "        psf_resid = psfphot.make_residual_image(img, psf_shape=(fit_shape, fit_shape))\n",
    "        logger.info(\"Image résiduelle calculée avec succès.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors du calcul de l'image résiduelle: {e}\")\n",
    "        raise\n",
    "\n",
    "    return phot, psf_resid\n",
    "\n",
    "# # Exemple d'utilisation :\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Supposons que bkg_subtracted_img, phot_table, std_x, std_y, i_fwhm et daostarfind soient définis\n",
    "#     try:\n",
    "#         phot, psf_resid = perform_psf_photometry(bkg_subtracted_img, phot_table, std_x, std_y, i_fwhm, daostarfind)\n",
    "#         logger.info(\"Photométrie PSF réalisée avec succès.\")\n",
    "#         print(phot)\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Échec de la photométrie PSF: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38fdf79-772e-4b81-9ebc-0c822f409d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_epsf_photometry(\n",
    "    img: np.ndarray,\n",
    "    phot_table: Table,\n",
    "    fwhm: float,\n",
    "    daostarfind: Any,  # On pourrait préciser Callable[..., Any] si la signature est connue\n",
    "    mask: Optional[np.ndarray] = None\n",
    ") -> Tuple[Table, Any]:\n",
    "    \"\"\"\n",
    "    Effectue la photométrie PSF en utilisant un modèle EPSF.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.ndarray\n",
    "        Image avec le fond de ciel soustrait.\n",
    "    phot_table : astropy.table.Table\n",
    "        Table contenant les positions des sources. Doit contenir au moins les colonnes 'xcenter' et 'ycenter'.\n",
    "    fwhm : float\n",
    "        Full Width at Half Maximum servant à définir la taille de l'ajustement.\n",
    "    daostarfind : callable\n",
    "        Fonction de détection des étoiles utilisée comme \"finder\" dans la photométrie PSF.\n",
    "    mask : np.ndarray, optional\n",
    "        Masque pour exclure certaines zones de l'image (par exemple, pixels non finis).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[astropy.table.Table, photutils.epsf.EPSF]\n",
    "        - phot_epsf : Résultats de la photométrie PSF avec le modèle EPSF.\n",
    "        - epsf : Modèle EPSF ajusté.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Préparer les données : conversion de l'image en objet NDData\n",
    "        nddata = NDData(data=img)\n",
    "        logger.info(\"NDData créé avec succès.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de la création de NDData: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Construction d'une table des étoiles à partir de phot_table\n",
    "        stars_table = Table()\n",
    "        stars_table['x'] = phot_table['xcenter']\n",
    "        stars_table['y'] = phot_table['ycenter']\n",
    "        logger.info(\"Table des positions d'étoiles préparée.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de la préparation de la table des étoiles: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Définir la forme de l'ajustement (taille de la boîte pour l'extraction des étoiles)\n",
    "        fit_shape = 2 * round(fwhm) + 1\n",
    "        logger.info(f\"Forme d'ajustement définie: {fit_shape} pixels.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors du calcul de la forme d'ajustement: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Extraction des étoiles dans la sous-image\n",
    "        stars = extract_stars(nddata, stars_table, size=fit_shape)\n",
    "        logger.info(f\"{len(stars)} étoiles extraites.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'extraction des étoiles: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Affichage des étoiles extraites (optionnel)\n",
    "        nrows, ncols = 5, 5\n",
    "        fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(5, 5), squeeze=False)\n",
    "        ax = ax.ravel()\n",
    "        n_disp = min(len(stars), nrows * ncols)\n",
    "        for i in range(n_disp):\n",
    "            norm = simple_norm(stars[i].data, 'log', percent=99.0)\n",
    "            ax[i].imshow(stars[i].data, norm=norm, origin='lower', cmap='viridis')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        logger.info(\"Affichage des étoiles extraites effectué.\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Erreur lors de l'affichage des étoiles extraites: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Construction et ajustement du modèle EPSF\n",
    "        epsf_builder = EPSFBuilder(oversampling=2, maxiters=5, progress_bar=True)\n",
    "        epsf, fitted_stars = epsf_builder(stars)\n",
    "        logger.info(\"Modèle EPSF ajusté avec succès.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'ajustement du modèle EPSF: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Affichage du modèle EPSF ajusté\n",
    "        norm = simple_norm(epsf.data, 'log', percent=99.)\n",
    "        plt.figure()\n",
    "        plt.imshow(epsf.data, norm=norm, origin='lower', cmap='viridis', interpolation='nearest')\n",
    "        plt.colorbar()\n",
    "        plt.title(\"Modèle EPSF ajusté\")\n",
    "        plt.show()\n",
    "        logger.info(\"Affichage du modèle EPSF effectué.\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Erreur lors de l'affichage du modèle EPSF: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Effectuer la photométrie PSF avec le modèle EPSF\n",
    "        psfphot = IterativePSFPhotometry(\n",
    "            epsf,\n",
    "            fit_shape,\n",
    "            finder=daostarfind,\n",
    "            aperture_radius=fit_shape / 2,\n",
    "            maxiters=3,\n",
    "            mode='new',\n",
    "            progress_bar=True\n",
    "        )\n",
    "        # Spécifier les positions des sources\n",
    "        psfphot.x = phot_table['xcenter']\n",
    "        psfphot.y = phot_table['ycenter']\n",
    "        logger.info(\"Positions des sources définies pour la photométrie PSF.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de la configuration de la photométrie PSF: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Exécuter la photométrie PSF avec le masque fourni\n",
    "        phot_epsf = psfphot(img, mask=mask)\n",
    "        logger.info(\"Photométrie EPSF effectuée avec succès.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'exécution de la photométrie EPSF: {e}\")\n",
    "        raise\n",
    "\n",
    "    return phot_epsf, epsf\n",
    "\n",
    "# # Exemple d'utilisation\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         # Supposons que bkg_subtracted_img, phot_table, i_fwhm, daostarfind et mask soient définis\n",
    "#         phot_epsf, epsf = perform_epsf_photometry(bkg_subtracted_img, phot_table, i_fwhm, daostarfind, mask)\n",
    "#         logger.info(\"Photométrie EPSF réalisée avec succès.\")\n",
    "#         print(phot_epsf)\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Échec de la photométrie EPSF: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c0722f-62b3-4a02-9a01-0e96eb8f9d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = airmass(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ffc83f-714e-459a-b74d-de5f7b5aec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, median, std, fwhm, pixel_scale = image_quality(img, img_wcs, seeing=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdedb52f-99f5-49c0-a3d8-e13e7ef55792",
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg = compute_background(img, sigma=3., box_size=(50, 50), filter_size=(5, 5))\n",
    "zscale_image(bkg.background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94f54be-3fbf-4bd4-a4ac-c775ee28f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = make_bord_mask(img, border=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e6bfb6-a0b7-45d0-af9b-38d42d1aa9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = img.astype(np.float)\n",
    "img_sub, bg = sep_subtract_background(new_img, bw=50, bh=50, fw=5, fh=5, fthresh=0.01)\n",
    "zscale_image(bg.back())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f92e8-b390-419f-a9e1-6f419b0a7a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pixel coordinates to celestial coordinates using the solved WCS\n",
    "pix_coords = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "ra_dec = im_wcs.all_pix2world(pix_coords, 0)\n",
    "sources['ra'] = ra_dec[:, 0]\n",
    "sources['dec'] = ra_dec[:, 1]\n",
    "\n",
    "# Create circular apertures\n",
    "radius = 1.5 * fwhm.value\n",
    "positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "apertures = aperture.CircularAperture(positions, \n",
    "                                      r=radius)\n",
    "\n",
    "# Perform aperture photometry on the stars\n",
    "phot_table = aperture.aperture_photometry(im_data_clean, apertures)\n",
    "phot_table['ra'] = sources['ra']\n",
    "phot_table['dec'] = sources['dec']\n",
    "\n",
    "# Convert the photometry table to a pandas DataFrame\n",
    "df = phot_table.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d42e2-b310-42f5-a9f4-1cfa91fceaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Gaia for reference stars within the circular region\n",
    "results = query_gaia(ra, dec, r.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd1f12-8e58-4cab-8330-d95ec54e1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas dataframe with the reference star coordinates and magnitudes\n",
    "ref_stars = pd.DataFrame({'id': results['source_id'],\n",
    "                          'ra': results['ra'], \n",
    "                          'dec': results['dec'], \n",
    "                          'mag': results['phot_rp_mean_mag']})\n",
    "\n",
    "# Convert the reference star coordinates to the same WCS as the target image\n",
    "ref_coords = SkyCoord(ra=ref_stars['ra'], \n",
    "                      dec=ref_stars['dec'], \n",
    "                      unit='deg',\n",
    "                      frame='icrs')\n",
    "coords = ref_coords.to_table()\n",
    "ref_pix_coords = im_wcs.all_world2pix(coords['ra'], coords['dec'], 0)\n",
    "\n",
    "ref_stars['x'] = ref_pix_coords[0]\n",
    "ref_stars['y'] = ref_pix_coords[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c162cc4c-a351-4aca-972b-c909977f5620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the reference stars to the detected stars\n",
    "detected_stars = df[['xcenter', 'ycenter','ra','dec']]\n",
    "detected_stars['aperture_sum'] = df['aperture_sum']\n",
    "detected_coords = SkyCoord(ra=df['ra'], dec=df['dec'], unit='deg', frame='icrs')\n",
    "idx, sep2d, dist3d = detected_coords.match_to_catalog_sky(ref_coords)\n",
    "detected_stars = detected_stars.to_pandas()\n",
    "\n",
    "match_mask = sep2d < 10*u.arcsec\n",
    "matched_refs = ref_stars.iloc[idx[match_mask]]\n",
    "matched_det = detected_stars.iloc[match_mask]\n",
    "print(matched_refs)\n",
    "print(matched_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb3cdf2-86b2-40b8-98a8-678402f1dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the photometric zeropoint\n",
    "kg = 0.2 #G - 0.1 #R\n",
    "m_inst = -2.5*np.log10(matched_det['aperture_sum']/60) + kg*airm\n",
    "m_ref = matched_refs['mag']\n",
    "\n",
    "dd = pd.DataFrame(columns=['mag_ref', 'mag_inst'])\n",
    "dd['mag_ref'] = m_ref.values\n",
    "dd['mag_inst'] = m_inst.values\n",
    "dd.dropna(inplace=True)\n",
    "\n",
    "z = np.array(dd['mag_ref'] - dd['mag_inst'])\n",
    "zp = np.median(z)\n",
    "zmad = scipy.stats.median_abs_deviation(z)\n",
    "zero.append([zp, zmad])\n",
    "\n",
    "# Apply the photometric zeropoint to the target stars\n",
    "df['mag'] = -2.5*np.log10(df['aperture_sum']/60) + zp + kg*airm\n",
    "dd['mag_inst'] = dd['mag_inst'] + zp\n",
    "\n",
    "df = df.to_pandas()\n",
    "df.sort_values(by='mag', ascending=True, inplace=True)\n",
    "\n",
    "print(f\"ZP : {zp}, ZMad : {zmad}\")\n",
    "print(f\"Stars matched : {len(dd)}\")\n",
    "\n",
    "d = dd.drop(dd[abs(dd['mag_ref'] - dd['mag_inst']) >= 1.].index)\n",
    "data_final.append(d)\n",
    "\n",
    "print(f\"Stars dropped delta >= 1. : {len(dd) - len(d)}\")\n",
    "print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b08dcd-400c-42e5-9013-b81e9d17ae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(6, 6))\n",
    "for i in data_final:\n",
    "    sb.regplot(x=d['mag_ref'],\n",
    "               y=d['mag_inst'], \n",
    "               robust=True)\n",
    "plt.grid()\n",
    "\n",
    "plt.figure(figsize =(6, 6))\n",
    "for i in data_final:\n",
    "    sb.residplot(x=i['mag_ref'], \n",
    "                 y=i['mag_inst'],\n",
    "                 lowess=True,\n",
    "                 robust=True, \n",
    "                 color='red')\n",
    "plt.ylim(-0.5, 0.5)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4b92a2-f782-4146-a530-eb38ef320a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = subprocess.Popen([\"C:\\SAOImageDS9\\ds9.exe\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "time.sleep(3)\n",
    "# viewer = imexam.connect()  # startup a new DS9 window\n",
    "# viewer.load_fits(fitsname)  # load a fits image into it\n",
    "# viewer.scale()  # run default zscaling on the image\n",
    "\n",
    "# Configurazione di SAMP\n",
    "client = SAMPIntegratedClient()\n",
    "client.connect()  # Connessione al server SAMP\n",
    "\n",
    "\n",
    "# Invio del file FITS a DS9\n",
    "try:\n",
    "    client.notify_all({\n",
    "        \"samp.mtype\": \"image.load.fits\",\n",
    "        \"samp.params\": {\n",
    "            \"url\": f\"file://{fitsname}\"\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    # Impostazioni di DS9 (zscale, zoomfit, etc.)\n",
    "    client.notify_all({\n",
    "        \"samp.mtype\": \"ds9.set\",\n",
    "        \"samp.params\": {\n",
    "            \"cmd\": \"zscale\"\n",
    "        }\n",
    "    })\n",
    "    client.notify_all({\n",
    "        \"samp.mtype\": \"ds9.set\",\n",
    "        \"samp.params\": {\n",
    "            \"cmd\": \"cmap viridis\"\n",
    "        }\n",
    "    })\n",
    "    client.notify_all({\n",
    "        \"samp.mtype\": \"ds9.set\",\n",
    "        \"samp.params\": {\n",
    "            \"cmd\": \"grid yes\"\n",
    "        }\n",
    "    })\n",
    "    client.notify_all({\n",
    "        \"samp.mtype\": \"ds9.set\",\n",
    "        \"samp.params\": {\n",
    "            \"cmd\": \"catalog import tsv catalogue.tsv\"\n",
    "        }\n",
    "    })\n",
    "    client.notify_all({\n",
    "        \"samp.mtype\": \"ds9.set\",\n",
    "        \"samp.params\": {\n",
    "            \"cmd\": \"zoom to fit\"\n",
    "        }\n",
    "    })\n",
    "    client.notify_all({\n",
    "        \"samp.mtype\": \"ds9.set\",\n",
    "        \"samp.params\": {\n",
    "            \"cmd\": \"smooth\"\n",
    "        }\n",
    "    })\n",
    "\n",
    "finally:\n",
    "    client.disconnect()  # Disconnessione dal server SAMP\n",
    "\n",
    "output, errors = p.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac77220d-8d45-495b-b7d2-592332f7dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 6.\n",
    "daofind = detection.DAOStarFinder(fwhm=2.*round(fwhm), threshold=sigma*std)\n",
    "sources = daofind(img - bkg.background, mask=mask)\n",
    "\n",
    "positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "\n",
    "# Tri des sources détectées par ordre décroissant de flux\n",
    "sources.sort(keys='flux', reverse=True)\n",
    "\n",
    "# Affichage du nombre de sources détectées\n",
    "sources = pretty_print(sources, precision=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21451865-2eab-4a6b-89b1-d1b9a1a93109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bkg subtracted image\n",
    "bkg_subtracted_img = img - bkg.background\n",
    "i_fwhm = fwhm_fit(bkg_subtracted_img, sources, fwhm, pixel_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7a3b9c-05cc-4aa2-a3d0-d851a89d9c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 3\n",
    "daostarfind = detection.DAOStarFinder(fwhm=2.*i_fwhm, threshold=sigma*std)\n",
    "final_sources = daostarfind(bkg_subtracted_img, mask=mask)\n",
    "\n",
    "mask_valid = ~np.isnan(final_sources['xcentroid']) & ~np.isnan(final_sources['ycentroid']) & \\\n",
    "             ~np.isinf(final_sources['xcentroid']) & ~np.isinf(final_sources['ycentroid'])\n",
    "final_sources = final_sources[mask_valid]\n",
    "\n",
    "positions = np.transpose((final_sources['xcentroid'], final_sources['ycentroid']))\n",
    "\n",
    "# Tri des sources détectées par ordre décroissant de flux\n",
    "final_sources.sort(keys='flux', reverse=True)\n",
    "\n",
    "# Affichage du nombre de sources détectées\n",
    "final_sources = pretty_print(final_sources, precision=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8d47f1-bcf8-4d5c-a342-4b12b3464f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_source_mask(data, nsigma, npixels, filter_fwhm=3.0, dilate_size=11):\n",
    "    \"\"\"\n",
    "    Crée un masque de sources à partir de données en utilisant une convolution et une détection de sources.\n",
    "\n",
    "    Parameters:\n",
    "    - data (numpy.ndarray): Image ou tableau de données à analyser.\n",
    "    - nsigma (np.float): Seuil en multiples d'écart-type pour la détection des sources.\n",
    "    - npixels (int): Nombre minimum de pixels connectés pour qu'une détection soit considérée comme une source.\n",
    "    - filter_fwhm (np.float, optional): Full Width at Half Maximum (FWHM) pour le noyau gaussien utilisé dans la convolution. La valeur par défaut est 3.0.\n",
    "    - dilate_size (int, optional): Taille du masque de dilatation pour agrandir le masque des sources détectées. La valeur par défaut est 11.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: Masque binaire où les sources détectées sont marquées.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Créer un noyau gaussien 2D pour la convolution\n",
    "    kernel = make_2dgaussian_kernel(filter_fwhm, size=3)\n",
    "    \n",
    "    # Convoluer les données avec le noyau gaussien\n",
    "    convolved_data = convolve(data, kernel)\n",
    "    \n",
    "    # Appliquer une coupure sigma pour filtrer les valeurs extrêmes\n",
    "    sigma_clip = SigmaClip(sigma=3.0, maxiters=5)\n",
    "    clipped_data = sigma_clip(data, masked=False)\n",
    "    \n",
    "    # Calculer la moyenne et l'écart-type des données coupées\n",
    "    mean_ = np.nanmean(clipped_data)\n",
    "    std_ = np.nanstd(clipped_data)\n",
    "    \n",
    "    # Définir le seuil pour la détection des sources basé sur nsigma\n",
    "    threshold_2sigma = mean_ + nsigma * std_\n",
    "    \n",
    "    # Détecter les sources dans les données convoluées\n",
    "    segm = detect_sources(convolved_data, threshold_2sigma, npixels)\n",
    "    \n",
    "    # Créer un masque de sources avec une dilatation\n",
    "    return segm.make_source_mask(size=dilate_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f044940b-ea0f-4c4c-b740-7cb5e21b2e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate_mask(mask, tophat_size):\n",
    "    \"\"\"\n",
    "    Dilate un masque binaire en utilisant un noyau top-hat 2D.\n",
    "\n",
    "    Cette fonction agrandit les régions du masque binaire en utilisant la convolution avec un noyau top-hat.\n",
    "    Les régions dilatées sont définies comme les zones où la valeur du masque convolué dépasse un seuil \n",
    "    basé sur la taille du noyau.\n",
    "\n",
    "    Parameters:\n",
    "    - mask (numpy.ndarray): Masque binaire d'entrée à dilater. Les valeurs doivent être 0 ou 1.\n",
    "    - tophat_size (np.float): Taille du noyau top-hat utilisé pour la dilatation. La taille est définie comme le diamètre du noyau.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: Masque dilaté, où les zones d'intérêt du masque d'origine sont étendues selon le noyau top-hat.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculer la surface du noyau top-hat\n",
    "    area = np.pi * tophat_size**2. \n",
    "    \n",
    "    # Créer un noyau top-hat 2D avec la taille spécifiée\n",
    "    kernel = Tophat2DKernel(tophat_size)\n",
    "    \n",
    "    # Convoluer le masque avec le noyau top-hat et appliquer le seuil\n",
    "    # Les régions où la valeur convoluée dépasse 1/area sont considérées comme dilatées\n",
    "    dilated_mask = convolve(mask, kernel) >= 1. / area\n",
    "    \n",
    "    return dilated_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aae754-2cf6-4348-b42d-1c78c0bf8dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourceMask:\n",
    "    \"\"\"\n",
    "    Classe pour créer et dilater un masque de sources à partir d'une image.\n",
    "\n",
    "    Cette classe fournit des méthodes pour créer un masque de sources à différentes échelles\n",
    "    et pour dilater ces masques en utilisant un noyau top-hat. Elle utilise les fonctions\n",
    "    `make_source_mask` et `dilate_mask` pour ces opérations.\n",
    "\n",
    "    Attributes:\n",
    "    - img (numpy.ndarray): Image sur laquelle le masque de sources sera créé.\n",
    "    - nsigma (np.float): Seuil en multiples d'écart-type pour la détection des sources.\n",
    "    - npixels (int): Nombre minimum de pixels connectés pour qu'une détection soit considérée comme une source.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img, nsigma=3., npixels=3):\n",
    "        \"\"\"\n",
    "        Initialise l'objet SourceMask.\n",
    "\n",
    "        Parameters:\n",
    "        - img (numpy.ndarray): Image sur laquelle le masque sera basé.\n",
    "        - nsigma (np.float, optional): Seuil en écarts-types pour la détection des sources. La valeur par défaut est 3.0.\n",
    "        - npixels (int, optional): Nombre minimum de pixels connectés pour la détection. La valeur par défaut est 3.\n",
    "        \"\"\"\n",
    "        self.img = img\n",
    "        self.nsigma = nsigma\n",
    "        self.npixels = npixels\n",
    "\n",
    "    def single(self, filter_fwhm=3., tophat_size=5., mask=None):\n",
    "        \"\"\"\n",
    "        Crée un masque de sources pour une seule échelle.\n",
    "\n",
    "        Cette méthode crée un masque de sources à une échelle spécifiée par `filter_fwhm` \n",
    "        et dilate ce masque en utilisant un noyau top-hat de taille `tophat_size`.\n",
    "\n",
    "        Parameters:\n",
    "        - filter_fwhm (np.float, optional): Full Width at Half Maximum pour le noyau gaussien utilisé dans la détection des sources. La valeur par défaut est 3.0.\n",
    "        - tophat_size (np.float, optional): Taille du noyau top-hat utilisé pour dilater le masque. La valeur par défaut est 5.0.\n",
    "        - mask (numpy.ndarray, optional): Masque binaire à soustraire de l'image avant la détection. La valeur par défaut est None.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: Masque dilaté pour une seule échelle.\n",
    "        \"\"\"\n",
    "        if mask is None:\n",
    "            image = self.img\n",
    "        else:\n",
    "            image = self.img * (1 - mask)\n",
    "        \n",
    "        # Créer le masque de sources à une échelle\n",
    "        mask = make_source_mask(image, nsigma=self.nsigma,\n",
    "                                npixels=self.npixels,\n",
    "                                dilate_size=1, filter_fwhm=filter_fwhm)\n",
    "        \n",
    "        # Dilater le masque créé\n",
    "        return dilate_mask(mask, tophat_size)\n",
    "\n",
    "    def multiple(self, filter_fwhm=[3.], tophat_size=[3.], mask=None):\n",
    "        \"\"\"\n",
    "        Crée un masque de sources à plusieurs échelles.\n",
    "\n",
    "        Cette méthode crée et dilate des masques de sources pour différentes échelles \n",
    "        spécifiées par `filter_fwhm` et `tophat_size`. Les masques à chaque échelle \n",
    "        sont combinés pour obtenir un masque final.\n",
    "\n",
    "        Parameters:\n",
    "        - filter_fwhm (list of np.float, optional): Liste des Full Width at Half Maximum pour les noyaux gaussiens utilisés dans la détection des sources. La valeur par défaut est [3.0].\n",
    "        - tophat_size (list of np.float, optional): Liste des tailles des noyaux top-hat utilisés pour dilater les masques. La valeur par défaut est [3.0].\n",
    "        - mask (numpy.ndarray, optional): Masque binaire à soustraire de l'image avant la détection. La valeur par défaut est None.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: Masque combiné dilaté pour toutes les échelles spécifiées.\n",
    "        \"\"\"\n",
    "        if mask is None:\n",
    "            self.mask = np.zeros(self.img.shape, dtype=bool)\n",
    "        \n",
    "        # Combiner les masques à différentes échelles\n",
    "        for fwhm, tophat in zip(filter_fwhm, tophat_size):\n",
    "            smask = self.single(filter_fwhm=fwhm, tophat_size=tophat, mask=mask)\n",
    "            self.mask = self.mask | smask  # Fusionner les masques à chaque itération\n",
    "        \n",
    "        return self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32789bd1-1ba2-4c38-ac5a-74d5af58971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_worst_residual_near_center(resid):\n",
    "    \"\"\"\n",
    "    Trouve la position du pixel avec le pire résidu près du centre, en évitant les bords.\n",
    "\n",
    "    Cette fonction recherche le pixel avec le plus grand résidu (valeur maximale) dans une région circulaire \n",
    "    centrée dans l'image, en évitant les bords de l'image. La région considérée est définie par un rayon\n",
    "    proportionnel à la taille de l'image.\n",
    "\n",
    "    Parameters:\n",
    "    - resid (numpy.ndarray): Image des résidus où chaque pixel représente un résidu calculé.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Coordonnées (ligne, colonne) du pixel avec le pire résidu dans la région définie.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculer les coordonnées du centre de l'image\n",
    "    yc, xc = resid.shape[0] / 2., resid.shape[1] / 2.\n",
    "    \n",
    "    # Définir le rayon de la région circulaire autour du centre pour éviter les bords\n",
    "    radius = resid.shape[0] / 3.\n",
    "    \n",
    "    # Créer des indices pour chaque pixel dans l'image\n",
    "    y, x = np.mgrid[0:resid.shape[0], 0:resid.shape[1]]\n",
    "    \n",
    "    # Créer un masque circulaire pour la région autour du centre\n",
    "    mask = np.sqrt((y - yc) ** 2 + (x - xc) ** 2) < radius\n",
    "    \n",
    "    # Appliquer le masque à l'image des résidus\n",
    "    rmasked = resid * mask\n",
    "    \n",
    "    # Trouver l'indice du pixel avec la valeur maximale dans la région masquée\n",
    "    return np.unravel_index(np.argmax(rmasked), resid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a4cf8d-2f69-4932-87ae-3d91a4e8b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mask(scene, bkgd, mask, zmin, zmax, worst=None, smooth=0):\n",
    "    \"\"\"\n",
    "    Crée un graphique en trois panneaux pour visualiser le masque et son impact sur l'image.\n",
    "\n",
    "    Les trois panneaux montrent :\n",
    "    1. Le masque appliqué à l'ensemble de l'image.\n",
    "    2. L'image `scene` après soustraction de l'image `bkgd` et application du masque.\n",
    "    3. Une région zoomée de l'image avec le masque superposé en contours.\n",
    "\n",
    "    Parameters:\n",
    "    - scene (numpy.ndarray): Image principale sur laquelle le masque est appliqué.\n",
    "    - bkgd (numpy.ndarray): Image de fond à soustraire de l'image principale.\n",
    "    - mask (numpy.ndarray): Masque binaire à appliquer à l'image.\n",
    "    - zmin (np.float): Valeur minimale pour l'échelle de couleurs de l'image.\n",
    "    - zmax (np.float): Valeur maximale pour l'échelle de couleurs de l'image.\n",
    "    - worst (tuple of int, optional): Coordonnées (x, y) du pixel avec le pire résidu à mettre en évidence. Si None, le pire résidu est déterminé automatiquement.\n",
    "    - smooth (np.float, optional): Taille du noyau gaussien pour lisser l'image après soustraction. Si 0, le lissage est désactivé. La valeur par défaut est 0.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Coordonnées (x, y) du pixel avec le pire résidu, ou celles fournies par `worst` si spécifié.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Déterminer les coordonnées du pire résidu\n",
    "    if worst is None:\n",
    "        y, x = find_worst_residual_near_center(bkgd - np.std(bkgd))\n",
    "    else:\n",
    "        x, y = worst\n",
    "    \n",
    "    # Créer une figure avec trois sous-graphes\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    # Premier panneau : afficher le masque\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(mask, vmin=0, vmax=1, cmap=plt.cm.gray, origin='lower')\n",
    "    plt.title(\"Mask\")\n",
    "    \n",
    "    # Deuxième panneau : afficher la scène après soustraction et application du masque\n",
    "    plt.subplot(132)\n",
    "    if smooth == 0:\n",
    "        plt.imshow((scene - bkgd) * (1 - mask), vmin=zmin, vmax=zmax, origin='lower')\n",
    "    else:\n",
    "        # Appliquer un lissage gaussien si spécifié\n",
    "        smoothed = convolve((scene - bkgd) * (1 - mask), Gaussian2DKernel(smooth))\n",
    "        plt.imshow(smoothed * (1 - mask), vmin=zmin / smooth, vmax=zmax / smooth, origin='lower')\n",
    "    plt.title(\"Scene with Mask Applied\")\n",
    "    \n",
    "    # Troisième panneau : afficher la scène avec le masque en contours\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(scene - bkgd, vmin=zmin, vmax=zmax)\n",
    "    plt.contour(mask, colors='red', alpha=0.2)\n",
    "    plt.title(\"Zoomed-In with Mask Contours\")\n",
    "    \n",
    "    # Retourner les coordonnées du pire résidu\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618115fd-aa3e-44e1-abc4-20bd7fa07d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_3sigma = make_source_mask(bkg_subtracted_img, nsigma=3, npixels=5,\n",
    "                               dilate_size=5, filter_fwhm=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ad8d33-0fd5-4b4c-ba5b-9cbc0b37e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zmin, zmax = np.percentile(bkg.background, (0.1, 99.9))\n",
    "sm = SourceMask(bkg_subtracted_img, nsigma=1.5)\n",
    "mask = sm.multiple(filter_fwhm=[1, 3, 5],\n",
    "                   tophat_size=[4, 2, 1])\n",
    "\n",
    "plot_mask(img, bkg.background, mask, zmin, zmax)\n",
    "\n",
    "bkg2 = compute_background(img, sigma=3., box_size=(35,50), filter_size=(5,7), mask=mask_3sigma)\n",
    "plot_2img(bkg.background, bkg2.background, zmin, zmax, titles=['', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8220b5a7-b33d-4f03-a3a6-4d7d4ae2a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from astropy.io import fits\n",
    "# from astropy.wcs import WCS\n",
    "# from astropy.stats import SigmaClip\n",
    "# from astropy.visualization import simple_norm\n",
    "# from photutils import Background2D, MedianBackground\n",
    "# from photutils.detection import DAOStarFinder\n",
    "# from photutils.aperture import CircularAperture, aperture_photometry\n",
    "# from astroquery.vizier import Vizier\n",
    "# from astropy.coordinates import SkyCoord\n",
    "# from astropy.table import Table, hstack\n",
    "# import astropy.units as u\n",
    "\n",
    "# # Step 1: Read the FITS file, extract data, header, and WCS information\n",
    "# filename = 'HorseHead.fits'\n",
    "# with fits.open(filename) as hdul:\n",
    "#     data = hdul[0].data\n",
    "#     header = hdul[0].header\n",
    "#     wcs = WCS(header)\n",
    "\n",
    "# # Step 2: Create a mask to exclude a border of 50 pixels around the edge of the image\n",
    "# border_size = 50\n",
    "# mask = np.zeros_like(data, dtype=bool)\n",
    "# mask[border_size:-border_size, border_size:-border_size] = True\n",
    "\n",
    "# # Step 3: Compute the background and remove it using a sigma clip of 3 sigma\n",
    "# sigma_clip = SigmaClip(sigma=3)\n",
    "# bkg_estimator = MedianBackground()\n",
    "# bkg = Background2D(data, (50, 50), filter_size=(3, 3), sigma_clip=sigma_clip, bkg_estimator=bkg_estimator, mask=~mask)\n",
    "# data_bkg_subtracted = data - bkg.background\n",
    "\n",
    "# # Step 4: Detect sources using DAO algorithm on 3 sigma threshold\n",
    "# daofind = DAOStarFinder(fwhm=1.5*i_fwhm, threshold=3.*np.median(bkg.background_rms))\n",
    "# sources = daofind(data_bkg_subtracted)\n",
    "\n",
    "# # Step 6: Compute aperture photometry on 1.5 and 2 FWHM and 2.5 radius\n",
    "# positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "# apertures = [CircularAperture(positions, r=r) for r in [1.5*i_fwhm, 2*i_fwhm, 2.5]]\n",
    "# phot_table = Table()\n",
    "\n",
    "# for aperture in apertures:\n",
    "#     phot = aperture_photometry(data_bkg_subtracted, aperture)\n",
    "#     phot_table = hstack([phot_table, phot])\n",
    "\n",
    "# # Step 7: Query Vizier using astroquery to search around a box with the same dimension of the image for standard sources\n",
    "# vizier = Vizier(columns=['RAJ2000', 'DEJ2000', 'Vmag'])\n",
    "# ra_center, dec_center = wcs.all_pix2world(data.shape[1] // 2, data.shape[0] // 2, 1)\n",
    "# coord_center = SkyCoord(ra_center, dec_center, unit='deg')\n",
    "# width = u.Quantity((data.shape[1], data.shape[0]), unit=u.pixel)\n",
    "# search_box = width * wcs.wcs.cdelt\n",
    "# result = vizier.query_region(coord_center, width=search_box, catalog='I/345/gaia2')\n",
    "\n",
    "# # Step 8: Cross-match the detected sources and the Vizier query with a maximum distance of 5 arcsec\n",
    "# std_sources = result[0]\n",
    "# detected_coords = SkyCoord(sources['xcentroid'], sources['ycentroid'], frame='icrs', unit='deg', obstime='J2000')\n",
    "# std_coords = SkyCoord(std_sources['RAJ2000'], std_sources['DEJ2000'], frame='icrs', unit='deg', obstime='J2000')\n",
    "\n",
    "# idx, d2d, _ = std_coords.match_to_catalog_sky(detected_coords)\n",
    "# match_mask = d2d < 5 * u.arcsec\n",
    "\n",
    "# matched_std_sources = std_sources[match_mask]\n",
    "# matched_detected_sources = sources[idx[match_mask]]\n",
    "\n",
    "# # Step 9: Calculate the zero point of the image using these sources\n",
    "# detected_fluxes = matched_detected_sources['flux']\n",
    "# std_magnitudes = matched_std_sources['Vmag']\n",
    "# zero_points = std_magnitudes + 2.5 * np.log10(detected_fluxes)\n",
    "# zero_point = np.mean(zero_points)\n",
    "\n",
    "# print(f\"Calculated zero point of the image: {zero_point:.2f} mag\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".astronomy",
   "language": "python",
   "name": ".astronomy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
